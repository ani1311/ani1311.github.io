<DOCTYPE html>
    <html>

    <head>
        <title>Aniket Alur</title>
        <link rel="shortcut icon" href="images/title.ico" />
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" rel="stylesheet"
            integrity="sha384-KyZXEAg3QhqLMpG8r+8fhAXLRk2vvoC2f3B09zVXn8CA5QIVfZOJ3BCsw2P0p/We" crossorigin="anonymous">
        <link rel="stylesheet" type="text/css" href="../../css/indexStyle.css">
        <link rel="stylesheet" type="text/css" href="../../css/blog.css">
    </head>

    <body>
        <div class="nav">
            <ul>
                <li><a href="/">Home</a></li>
                <li><a href="/blog.html">Blog</a></li>
                <li><a href="/projects.html">Projects</a></li>
                <li><a href="/contactMe.html">Contact Me</a></li>
                <li><a href="/Resume.pdf">Resume</a></li>
                <li><a href="/p5jsProjects.html">p5js Projects</a></li>
            </ul>
        </div>


        <div class="blogtitlebox">
            <h1>Decentralized (Tree) Index Of The Internet</h1>
            <h3>by Aniket Alur</h3>
            <h5>November 23, 2021</h5>
        </div>
        <div class="blogcolorbox">
            <div class="blogtextbox">

                Okay, what is the internet? essentially just a big graph of webpages. So is there be an easy way to
                see the entier internet. Now there are two challenges in this.
                <br>
                <br>

                => Who will run all that compute of crawllers.<br>
                => Where to store graph.

                <br>
                <br>

                <h2> The Idea:</h2>

                A network where each node explores/updates some part of the internet. And each node can have a list of
                websites it tracks.<br>
                These nodes run crawllers and store the result of these crawllers.

                <br>
                <br>

                <h3> Why do this?</h3>
                Well, for starters, if I want to scrape the web for data, this would be a fantastic resource. But more
                importantly, I don't know how or where someone might come up with an application that uses this API. But
                a publicly available index of the Internet should have been a resource available years ago.
                <br>

                In addition, if someone can build a good parser, identifier, then this can server as a great tool to
                build new pages. We have hackerNews, but this might help build AritstNews or paleontologistNews.

                We can build systems to categorize websites, build niche specific search engines.

                <br>
                <br>
                <br>

                <h2> How?</h2>

                <h3> The Crawller:</h3>
                This is the main compute that will run on each node.
                <br>
                <a href="https://github.com/ani1311/Spider">Spider in golang</a>
                <br>
                <br>
                <h3> The Database</h3>
                What we need to store. Consider that there is a node that is the root of each domain. Now this root will
                have a tree of all the pages in that domain. But any node in this tree may also be refered by a node in
                some other tree outside the domain. This way, the web forms a graph, and we need a structure to store
                this graph.

                A complete index of the internet containing links to the pages of most(Possibly every website) will have
                a size in the order of terabytes. This can not be feasible stored in every node. We need the data base
                to have the following properties:<br>
                -> It must be mutable by any node in the network.

                <br>
                <br>

                We can use <a href="https://ipfs.io/">IPFS</a> to store the base DB. This distributes the data over
                multiple IPFS nodes ensuring the
                integrity of the entire store.
                <br>


                <br>
                <br>

                <h2> Who will run these nodes?</h2>
                If I want my website to be in the index, I will somehow run the node, either by paying or running my own
                node(TBD)

            </div>
        </div>

        <footer>
            <!-- <br>
        <br>
        <br>
        <br> -->
        </footer>

    </body>

    </html>
